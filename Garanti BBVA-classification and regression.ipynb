{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = pd.read_csv(\"C://Users/Furkan/Desktop/onlinedatasciencechallenge/train.csv\")\n",
    "test_input = pd.read_csv(\"C://Users/Furkan/Desktop/onlinedatasciencechallenge/test_input.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_input.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = train_data.iloc[:,2]\n",
    "#dates = train_data.iloc[:,1]\n",
    "train_data = train_data.iloc[:,3:]\n",
    "train_data = pd.concat([train_data,y],axis=1)\n",
    "#train_data = pd.concat([dates,train_data],axis=1)\n",
    "test_data = test_input.iloc[:,2:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(train_data.shape)\n",
    "print(test_data.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 'CONTPAIDAMNT07' kolonunun test veri setinde eksik olduğunu görüyoruz ve verilerden atıyoruz."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(train_data.columns)\n",
    "print(test_data.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data.drop('CONTPAIDAMNT07', axis=1, inplace=True)\n",
    "train_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in train_data.columns:\n",
    "    print(col, str(round(100* train_data[col].isnull().sum() / len(train_data), 2)) + '%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### \"BLNAMNT03\", \"EFTAMNTSUM12\",\"DEBTAVG00\" \"LASTAUTOPAYTIME\", \"TIMEDEPAVG12\" kolonlarını eksik veriden dolayı atmak zorundayız.\n",
    "## Veri kaybının %50'den fazla olduğu kolonlar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data.drop([\"BLNAMNT03\",\"EFTAMNTSUM12\",\"DEBTAVG00\",\"LASTAUTOPAYTIME\",\"TIMEDEPAVG12\"], axis=1, inplace=True)\n",
    "test_data.drop([\"BLNAMNT03\",\"EFTAMNTSUM12\",\"DEBTAVG00\",\"LASTAUTOPAYTIME\",\"TIMEDEPAVG12\"], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_columns', None)\n",
    "\n",
    "train_data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = train_data.dropna(how=\"any\",axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data.fillna(train_data.mean(),inplace=True)\n",
    "test_data.fillna(test_data.mean(),inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data.describe().T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Outlier değerlerden kurtulmak için IsolationForest kullanıyoruz."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import IsolationForest\n",
    "iso = IsolationForest(contamination=0.25)\n",
    "yhat = iso.fit_predict(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = yhat != -1\n",
    "\n",
    "train_inlier = train_data.iloc[mask,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_inlier.describe().T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_inlier.corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data.loc[train_data.ADDCONTAMNT != 0, \"ADDCONTAMNT\"] = 1\n",
    "#train_inlier.loc[train_inlier.ADDCONTAMNT != 0, \"ADDCONTAMNT\"] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data.head()\n",
    "#train_inlier.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_data = train_data.iloc[:,-1]\n",
    "#y_inlier = train_inlier.iloc[:,-1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data.drop(\"ADDCONTAMNT\",axis=1, inplace=True)\n",
    "#train_inlier.drop(\"ADDCONTAMNT\",axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modelling\n",
    "\n",
    "first classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "x_train, x_test, y_train, y_test = train_test_split(train_data, y_data, test_size=0.3, random_state=8)\n",
    "#x_train, x_test, y_train, y_test = train_test_split(train_inlier, y_inlier, test_size=0.3, random_state=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "ss = StandardScaler()\n",
    "x_train = ss.fit_transform(x_train)\n",
    "x_test = ss.transform(x_test)\n",
    "\n",
    "from sklearn.metrics import mean_squared_error, r2_score, confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error, r2_score, confusion_matrix\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "logreg = LogisticRegression(random_state = 0)\n",
    "logreg.fit(x_train, y_train)\n",
    "logreg_pred = logreg.predict(x_test)\n",
    "\n",
    "print(\"R^2 Score: \" + str(r2_score(y_test,logreg_pred)))\n",
    "print(\"RMSE: \" + str(mean_squared_error(y_test,logreg_pred, squared=False)))\n",
    "print(\"Confusion matrix:\")\n",
    "print(confusion_matrix(y_test,logreg_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "knn = KNeighborsClassifier(n_neighbors = 3)\n",
    "knn.fit(x_train,y_train)\n",
    "knn_pred = knn.predict(x_test)\n",
    "\n",
    "print(\"R^2 Score: \" + str(r2_score(y_test,knn_pred)))\n",
    "print(\"RMSE: \" + str(mean_squared_error(y_test,knn_pred, squared=False)))\n",
    "print(\"Confusion matrix:\")\n",
    "print(confusion_matrix(y_test,knn_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "svc = SVC(kernel=\"linear\")\n",
    "svc.fit(x_train,y_train)\n",
    "svc_pred = svc.predict(x_test)\n",
    "\n",
    "print(\"R^2 Score: \" + str(r2_score(y_test,svc_pred)))\n",
    "print(\"RMSE: \" + str(mean_squared_error(y_test,svc_pred, squared=False)))\n",
    "print(\"Confusion matrix:\")\n",
    "print(confusion_matrix(y_test,svc_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "gnb = GaussianNB\n",
    "gnb.fit(x_train, y_train)\n",
    "gnb_pred = gnb.predict(x_test)\n",
    "\n",
    "print(\"R^2 Score: \" + str(r2_score(y_test,gnb_pred)))\n",
    "print(\"RMSE: \" + str(mean_squared_error(y_test,gnb_pred, squared=False)))\n",
    "print(\"Confusion matrix:\")\n",
    "print(confusion_matrix(y_test,gnb_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "dtc = DecisionTreeClassifier(max_depth= 7, criterion = \"entropy\")\n",
    "dtc.fit(x_train,y_train)\n",
    "dtc_pred = dtc.predict(x_test)\n",
    "\n",
    "print(\"R^2 Score: \" + str(r2_score(y_test,dtc_pred)))\n",
    "print(\"RMSE: \" + str(mean_squared_error(y_test,dtc_pred, squared=False)))\n",
    "print(\"Confusion matrix:\")\n",
    "print(confusion_matrix(y_test,dtc_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "rfc = RandomForestClassifier(n_estimators = 100, criterion = \"gini\")\n",
    "rfc.fit(x_train,y_train)\n",
    "rfc_pred = rfc.predict(x_test)\n",
    "#rfc_pred2 = rfc.predict(test_data)\n",
    "\n",
    "print(\"R^2 Score: \" + str(r2_score(y_test,rfc_pred)))\n",
    "print(\"RMSE: \" + str(mean_squared_error(y_test,rfc_pred, squared=False)))\n",
    "print(\"Confusion matrix:\")\n",
    "print(confusion_matrix(y_test,rfc_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBClassifier\n",
    "classifier = XGBClassifier()\n",
    "classifier.fit(x_train, y_train)\n",
    "xg_pred = classifier.predict(x_test)\n",
    "#xg_pred2 = classifier.predict(test_data)\n",
    "\n",
    "print(\"R^2 Score: \" + str(r2_score(y_test,xg_pred)))\n",
    "print(\"RMSE: \" + str(mean_squared_error(y_test,xg_pred, squared=False)))\n",
    "print(\"Confusion matrix:\")\n",
    "print(confusion_matrix(y_test,xg_pred))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modelling\n",
    "\n",
    "Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "ss = StandardScaler()\n",
    "x_train = ss.fit_transform(x_train)\n",
    "x_test = ss.transform(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "lr = LinearRegression()\n",
    "lr.fit(x_train,y_train)\n",
    "lr_pred = lr.predict(x_test)\n",
    "\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "print(\"R^2 Score: \" + str(r2_score(y_test,lr_pred)))\n",
    "print(\"RMSE: \" + str(mean_squared_error(y_test,lr_pred, squared=False)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import LinearSVR\n",
    "kernel = [\"linear\", \"poly\", \"rbf\", \"sigmoid\", \"precomputed\"]\n",
    "\n",
    "svr = LinearSVR()\n",
    "svr.fit(x_train,y_train)\n",
    "svr_pred = svr.predict(x_test)\n",
    "\n",
    "print(\"R^2 Score: \" + str(r2_score(y_test,svr_pred)))\n",
    "print(\"RMSE: \" + str(mean_squared_error(y_test,svr_pred, squared=False)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeRegressor\n",
    "dtr = DecisionTreeRegressor(max_depth=None, criterion = \"mse\", min_samples_split = 2,min_samples_leaf= 7)\n",
    "dtr.fit(x_train,y_train)\n",
    "dtr_pred = dtr.predict(x_test)\n",
    "dtr2_pred = dtr.predict(test_data)\n",
    "\n",
    "print(\"R^2 Score: \" + str(r2_score(y_test,dtr_pred)))\n",
    "print(\"RMSE: \" + str(mean_squared_error(y_test,dtr_pred, squared=False)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "rfr = RandomForestRegressor(n_estimators = 100, criterion = \"mse\")\n",
    "rfr.fit(x_train,y_train)\n",
    "rfr_pred = rfr.predict(x_test)\n",
    "\n",
    "print(\"R^2 Score: \" + str(r2_score(y_test,rfr_pred)))\n",
    "print(\"RMSE: \" + str(mean_squared_error(y_test,rfr_pred, squared=False)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = pd.DataFrame({'Id': test_input[\"CUSTNBR\"], 'Predicted': dtr2_pred})\n",
    "output.to_csv('denemesub.csv', index=False)\n",
    "print(\"Your submission was successfully saved!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
